{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f6de7f",
   "metadata": {},
   "source": [
    "# ANN with Two Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c194528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk import word_tokenize, ngrams\n",
    "from nltk.classify import SklearnClassifier\n",
    "np.random.seed(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07decc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading train CSV file directly from Web, and store it in a pandas DataFrame:\n",
    "train = pd.read_csv('D:/Fauzan/Study PhD/Semester 1/Machine Learning/Homework/HW4/spooky-author-identification/spooky-author-identification/train/train.csv')\n",
    "\n",
    "# Print first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c820032f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading test CSV file directly from Web, and store it in a pandas DataFrame:\n",
    "test = pd.read_csv(\"D:/Fauzan/Study PhD/Semester 1/Machine Learning/Homework/HW4/spooky-author-identification/spooky-author-identification/test/test.csv\")\n",
    "\n",
    "# Print first 5 rows\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ba4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Mapping\n",
    "mapping_target = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "train = train.replace({'author':mapping_target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d43ce2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test['id']\n",
    "target = train['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acf40465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean data\n",
    "import string\n",
    "import itertools \n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace(\"' \", \" ' \")\n",
    "    signs = set(',.:;\"?!')\n",
    "    prods = set(text) & signs\n",
    "    if not prods:\n",
    "        return text\n",
    "\n",
    "    for sign in prods:\n",
    "        text = text.replace(sign, ' {} '.format(sign) )\n",
    "    return text\n",
    "\n",
    "def cleanData(text, lowercase = False, remove_stops = False, stemming = False, lemmatization = False):\n",
    "    \n",
    "    txt = str(text)\n",
    "    \n",
    "    txt = re.sub(r'[^A-Za-z\\s]',r' ',txt)\n",
    "    \n",
    "     \n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "        \n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    if stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    \n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos='v') for w in txt.split()])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d54ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].map(lambda x: preprocess(x))\n",
    "test['text'] = test['text'].map(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b47235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text\n",
    "train['text'] = train['text'].map(lambda x: cleanData(x, lowercase=True, remove_stops=False, stemming=False, lemmatization = False))\n",
    "test['text'] = test['text'].map(lambda x: cleanData(x, lowercase=True, remove_stops=False, stemming=False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bd7ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(25)\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4df3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 256\n",
    "MAX_NB_WORDS = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f45630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ngram(q, n_gram_max):\n",
    "            ngrams = []\n",
    "            for n in range(2, n_gram_max+1):\n",
    "                for w_index in range(len(q)-n+1):\n",
    "                    ngrams.append('--'.join(q[w_index:w_index+n]))\n",
    "            return q + ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acbf9def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Found 19579 texts.\n",
      "Found 8392 texts.\n"
     ]
    }
   ],
   "source": [
    "n_gram_max = 2\n",
    "print('Processing text dataset')\n",
    "texts_1 = []\n",
    "for text in train['text']:\n",
    "    text = text.split()\n",
    "    texts_1.append(' '.join(add_ngram(text, n_gram_max)))\n",
    "    \n",
    "\n",
    "labels = train['author']  # list of label ids\n",
    "\n",
    "print('Found %s texts.' % len(texts_1))\n",
    "test_texts_1 = []\n",
    "for text in test['text']:\n",
    "    text = text.split()\n",
    "    test_texts_1.append(' '.join(add_ngram(text, n_gram_max)))\n",
    "print('Found %s texts.' % len(test_texts_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39a11878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (19579, 256)\n",
      "Shape of label tensor: (19579,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "843"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count = 2\n",
    "tokenizer = Tokenizer(lower=False, filters='')\n",
    "tokenizer.fit_on_texts(texts_1)\n",
    "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\n",
    "tokenizer.fit_on_texts(texts_1)\n",
    "\n",
    "\n",
    "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
    "# word_index = tokenizer.word_index\n",
    "# print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "test_sequences_1 = tokenizer.texts_to_sequences(test_texts_1)\n",
    "\n",
    "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Shape of data tensor:', data_1.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "#test_labels = np.array(test_labels)\n",
    "del test_sequences_1\n",
    "del sequences_1\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d50282",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words = np.max(data_1) + 1 #min(MAX_NB_WORDS, len(word_index)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be80c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Conv1D(64, 5, padding='valid', activation='relu', batch_input_shape=(None, MAX_SEQUENCE_LENGTH, 1)))\n",
    "model.add(Dense(16, activation = 'relu', input_dim = MAX_SEQUENCE_LENGTH))\n",
    "# model.add(Embedding(nb_words,3,input_length=MAX_SEQUENCE_LENGTH))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2dfdf95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 16)                4112      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,163\n",
      "Trainable params: 4,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62d69857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 550.7497 - accuracy: 0.3762 - val_loss: 14.5507 - val_accuracy: 0.3933\n",
      "Epoch 2/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 5.0365 - accuracy: 0.4011 - val_loss: 3.7502 - val_accuracy: 0.3943\n",
      "Epoch 3/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.7885 - accuracy: 0.4025 - val_loss: 2.3830 - val_accuracy: 0.3950\n",
      "Epoch 4/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.2708 - accuracy: 0.4041 - val_loss: 2.0516 - val_accuracy: 0.3963\n",
      "Epoch 5/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.1960 - accuracy: 0.4044 - val_loss: 1.7899 - val_accuracy: 0.3963\n",
      "Epoch 6/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.1366 - accuracy: 0.4049 - val_loss: 1.4665 - val_accuracy: 0.3981\n",
      "Epoch 7/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.1274 - accuracy: 0.4047 - val_loss: 1.1994 - val_accuracy: 0.3996\n",
      "Epoch 8/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.1453 - accuracy: 0.4048 - val_loss: 1.1398 - val_accuracy: 0.3999\n",
      "Epoch 9/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.0871 - accuracy: 0.4048 - val_loss: 1.1400 - val_accuracy: 0.4002\n",
      "Epoch 10/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.0857 - accuracy: 0.4049 - val_loss: 1.1410 - val_accuracy: 0.4002\n",
      "Epoch 11/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.0862 - accuracy: 0.4048 - val_loss: 1.1420 - val_accuracy: 0.4002\n",
      "Epoch 12/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.0856 - accuracy: 0.4049 - val_loss: 1.1437 - val_accuracy: 0.4002\n",
      "Epoch 13/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.0854 - accuracy: 0.4049 - val_loss: 1.1438 - val_accuracy: 0.4002\n",
      "Epoch 14/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.0861 - accuracy: 0.4049 - val_loss: 1.1588 - val_accuracy: 0.3999\n",
      "Epoch 15/15\n",
      "979/979 [==============================] - 2s 2ms/step - loss: 1.0868 - accuracy: 0.4048 - val_loss: 1.1446 - val_accuracy: 0.4002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2335a283a60>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_1, to_categorical(labels), validation_split=0.2, epochs=15, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d0a25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75bc9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result['id'] = test_id\n",
    "result['EAP'] = [x[0] for x in preds]\n",
    "result['HPL'] = [x[1] for x in preds]\n",
    "result['MWS'] = [x[2] for x in preds]\n",
    "\n",
    "result.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb8867e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.402314</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.308621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.402314</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.308621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.402314</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.308621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.402314</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.308621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.402314</td>\n",
       "      <td>0.289065</td>\n",
       "      <td>0.308621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       EAP       HPL       MWS\n",
       "0  id02310  0.402314  0.289065  0.308621\n",
       "1  id24541  0.402314  0.289065  0.308621\n",
       "2  id00134  0.402314  0.289065  0.308621\n",
       "3  id27757  0.402314  0.289065  0.308621\n",
       "4  id04081  0.402314  0.289065  0.308621"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
